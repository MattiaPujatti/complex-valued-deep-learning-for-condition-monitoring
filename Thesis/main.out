\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{Intro}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Previous work}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.3}{Neuronal Synchrony}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.4}{Thesis Organization}{chapter.1}% 5
\BOOKMARK [-1][-]{part.1}{I Complex-Valued Deep Learning}{}% 6
\BOOKMARK [0][-]{chapter.2}{Complex Analysis}{part.1}% 7
\BOOKMARK [1][-]{section.2.1}{Complex Numbers}{chapter.2}% 8
\BOOKMARK [1][-]{section.2.2}{Complex Differentiability}{chapter.2}% 9
\BOOKMARK [1][-]{section.2.3}{Other theorems}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.4}{Circularity}{chapter.2}% 11
\BOOKMARK [1][-]{section.2.5}{Why not to prefer real-valued network with two channels?}{chapter.2}% 12
\BOOKMARK [0][-]{chapter.3}{Extent}{part.1}% 13
\BOOKMARK [1][-]{section.3.1}{Problems in the extent}{chapter.3}% 14
\BOOKMARK [1][-]{section.3.2}{Complex Backpropagation}{chapter.3}% 15
\BOOKMARK [2][-]{subsection.3.2.1}{Steepest Complex Gradient Descent}{section.3.2}% 16
\BOOKMARK [2][-]{subsection.3.2.2}{Backpropagation with a Real-valued Loss}{section.3.2}% 17
\BOOKMARK [1][-]{section.3.3}{Re-definition of the main neural network layers}{chapter.3}% 18
\BOOKMARK [1][-]{section.3.4}{Complex-Valued Activation Functions}{chapter.3}% 19
\BOOKMARK [1][-]{section.3.5}{JAX Implementation}{chapter.3}% 20
\BOOKMARK [0][-]{appendix.A}{Mathematical Proofs}{part.1}% 21
\BOOKMARK [1][-]{section.A.1}{Complex Weights Initialization trabelsi2018deep}{appendix.A}% 22
\BOOKMARK [1][-]{section.A.2}{Stationary points of a real-valued function of a complex variable Messerschmittstationarypoints}{appendix.A}% 23
\BOOKMARK [1][-]{section.A.3}{Steepest complex gradient descent Hualiangnonlinear}{appendix.A}% 24
