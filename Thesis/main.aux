\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{trabelsi2018deep}
\citation{Messerschmitt_stationary_points}
\citation{Hualiang_nonlinear}
\citation{Dramsch_seismic}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{vii}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Intro}{vii}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Previous work}{vii}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Neuronal Synchrony}{vii}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Thesis Organization}{vii}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Complex-Valued Deep Learning}{ix}{part.1}\protected@file@percent }
\citation{stein_complex_analysis}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Complex Analysis}{xi}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Complex Numbers}{xi}{section.2.1}\protected@file@percent }
\newlabel{sec:cmplx_numbers}{{2.1}{xi}{Complex Numbers}{section.2.1}{}}
\citation{Messerschmitt_stationary_points}
\citation{kreutzdelgado2009complex}
\newlabel{obs:cmplx_mult_homothety}{{2.1.1}{xii}{}{observation.2.1.1}{}}
\newlabel{def:cmplx_der}{{2.1.3}{xii}{}{definition.2.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Complex Differentiability}{xiii}{section.2.2}\protected@file@percent }
\newlabel{sec:cmplx_differentiability}{{2.2}{xiii}{Complex Differentiability}{section.2.2}{}}
\newlabel{eq:CR_derivs}{{2.2}{xiii}{Complex Differentiability}{equation.2.2.2}{}}
\newlabel{eq:CR_derivs_chain_rule}{{2.3}{xiii}{Complex Differentiability}{equation.2.2.3}{}}
\newlabel{eq:CR_calc_identities_1}{{2.4}{xiii}{Complex Differentiability}{equation.2.2.4}{}}
\newlabel{eq:CR_calc_identities_2}{{2.5}{xiii}{Complex Differentiability}{equation.2.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Other theorems}{xiii}{section.2.3}\protected@file@percent }
\citation{Nitta_complexBP}
\citation{barrachina2021complexvalued}
\newlabel{th:Liouville}{{2.3.1}{xiv}{}{theorem.2.3.1}{}}
\newlabel{th:identity}{{2.3.2}{xiv}{}{theorem.2.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Circularity}{xiv}{section.2.4}\protected@file@percent }
\newlabel{sec:circularity}{{2.4}{xiv}{Circularity}{section.2.4}{}}
\citation{Virtue:EECS-2019-126}
\citation{Virtue:EECS-2019-126}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of a perfectly circular distribution $(\rho _z=0)$ and a non-circular one (right).\relax }}{xv}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:circular_distrib}{{2.1}{xv}{Example of a perfectly circular distribution $(\rho _z=0)$ and a non-circular one (right).\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Why not to prefer real-valued network with two channels?}{xv}{section.2.5}\protected@file@percent }
\newlabel{subsec:cmplx_multiplication}{{2.5}{xv}{Complex Multiplication}{section*.6}{}}
\citation{Virtue:EECS-2019-126}
\citation{Virtue:EECS-2019-126}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Visual representation of the multiplication and the corresponding implementation in a complex-valued network (bottom left). In order to replicate the same behavior on a real-valued network, the weights' components must be replicated, or shared, in the 2-channels layer (on the right). (source:\cite  {Virtue:EECS-2019-126})\relax }}{xvi}{figure.caption.7}\protected@file@percent }
\newlabel{fig:cmplx_multiplication}{{2.2}{xvi}{Visual representation of the multiplication and the corresponding implementation in a complex-valued network (bottom left). In order to replicate the same behavior on a real-valued network, the weights' components must be replicated, or shared, in the 2-channels layer (on the right). (source:\cite {Virtue:EECS-2019-126})\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Visual representation of the complex multiplication (center) compared to its real-valued implementations (1-ch left, 2-ch right). (source:\cite  {Virtue:EECS-2019-126})\relax }}{xvi}{figure.caption.8}\protected@file@percent }
\newlabel{fig:mult_dof}{{2.3}{xvi}{Visual representation of the complex multiplication (center) compared to its real-valued implementations (1-ch left, 2-ch right). (source:\cite {Virtue:EECS-2019-126})\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Extent}{xix}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problems in the extent}{xix}{section.3.1}\protected@file@percent }
\newlabel{sec:problems_extent}{{3.1}{xix}{Problems in the extent}{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Fundamental unit (neuron) of a complex-valued neural network.\relax }}{xix}{figure.caption.10}\protected@file@percent }
\newlabel{fig:cmplx_neuron}{{3.1}{xix}{Fundamental unit (neuron) of a complex-valued neural network.\relax }{figure.caption.10}{}}
\citation{Nitta_complexBP}
\citation{Nitta_complexBP}
\citation{hirose_cvnn}
\citation{amin_wirtinger}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Complex Backpropagation}{xxi}{section.3.2}\protected@file@percent }
\newlabel{sec:cmplx_backpropagation}{{3.2}{xxi}{Complex Backpropagation}{section.3.2}{}}
\citation{amin_wirtinger,Hualiang_nonlinear}
\citation{Virtue:EECS-2019-126}
\citation{Virtue:EECS-2019-126}
\citation{Virtue:EECS-2019-126}
\citation{Virtue:EECS-2019-126}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Steepest Complex Gradient Descent}{xxii}{subsection.3.2.1}\protected@file@percent }
\newlabel{sec:steepest_cmplx_gradient_descent}{{3.2.1}{xxii}{Steepest Complex Gradient Descent}{subsection.3.2.1}{}}
\newlabel{eq:cmplx_gradient_descent}{{3.1}{xxii}{Steepest Complex Gradient Descent}{equation.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Complex Gradient Descent.\relax }}{xxii}{figure.caption.15}\protected@file@percent }
\newlabel{fig:cmplx_gradient_descent}{{3.2}{xxii}{Complex Gradient Descent.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Backpropagation with a Real-valued Loss}{xxii}{subsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Forward and backward pass through a complex layer. (source \cite  {Virtue:EECS-2019-126})\relax }}{xxii}{figure.caption.17}\protected@file@percent }
\newlabel{fig:visual_cmplx_backpropagation}{{3.3}{xxii}{Forward and backward pass through a complex layer. (source \cite {Virtue:EECS-2019-126})\relax }{figure.caption.17}{}}
\citation{xavier_init}
\citation{he2015delving}
\citation{trabelsi2018deep}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Comparison of backpropagation calculus. (source: \cite  {Virtue:EECS-2019-126})\relax }}{xxiii}{table.caption.16}\protected@file@percent }
\newlabel{tab:comparison_backpropagation}{{3.1}{xxiii}{Comparison of backpropagation calculus. (source: \cite {Virtue:EECS-2019-126})\relax }{table.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Re-definition of the main neural network layers}{xxiii}{section.3.3}\protected@file@percent }
\citation{trabelsi2018deep}
\citation{trabelsi2018deep}
\citation{trabelsi2018deep}
\citation{trabelsi2018deep}
\newlabel{eq:cmplx_convolution}{{3.2}{xxiv}{Convolutional Layers}{equation.3.3.2}{}}
\citation{cogswell2016reducing}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Implementation details of the Complex Convolution (by \cite  {trabelsi2018deep}).\relax }}{xxv}{figure.caption.20}\protected@file@percent }
\newlabel{fig:cmplx_convolution}{{3.4}{xxv}{Implementation details of the Complex Convolution (by \cite {trabelsi2018deep}).\relax }{figure.caption.20}{}}
\newlabel{eq:cmplx_batchnorm}{{3.3}{xxv}{Normalization Layers}{equation.3.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Complex-Valued Activation Functions}{xxvi}{section.3.4}\protected@file@percent }
\citation{Virtue:EECS-2019-126}
\citation{Nitta_complexBP}
\citation{Nitta_complexBP}
\citation{trabelsi2018deep}
\citation{guberman2016complex}
\citation{Koutsougeras_siglog}
\citation{Virtue:EECS-2019-126}
\citation{DBLP:journals/corr/ArjovskySB15}
\citation{Virtue:EECS-2019-126}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Recal of the most popular complex-valued activation functions.\relax }}{xxviii}{table.caption.29}\protected@file@percent }
\newlabel{tab:cmplx_activations}{{3.2}{xxviii}{Recal of the most popular complex-valued activation functions.\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}JAX Implementation}{xxviii}{section.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces JAX logo.\relax }}{xxix}{figure.caption.30}\protected@file@percent }
\citation{barrachina2021complexvalued}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Complex-Valued vs Real Neural Networks}{xxxi}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Complex vs Real Models}{xxxi}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Impact of the Circularity}{xxxi}{section.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Samples coming from a perfectly circular distribution (left) and from a non-circular one (right).\relax }}{xxxii}{figure.caption.33}\protected@file@percent }
\newlabel{fig:circ_class_example}{{4.1}{xxxii}{Samples coming from a perfectly circular distribution (left) and from a non-circular one (right).\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Classification accuracy for real and complex-valued networks as function of different source of non-circularity.\relax }}{xxxiii}{figure.caption.35}\protected@file@percent }
\newlabel{fig:noncirc_results}{{4.2}{xxxiii}{Classification accuracy for real and complex-valued networks as function of different source of non-circularity.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Comparison of the accuracy achieved by a complex-valued model (left) and its real equivalent counterpart (center) in distinguishing a perfectly circular distribution from a second one as function of its circularity quotient. The third plot (right), instead, represents simply the differences among the first two.\relax }}{xxxiv}{figure.caption.36}\protected@file@percent }
\newlabel{fig:noncirc_comparison_final}{{4.3}{xxxiv}{Comparison of the accuracy achieved by a complex-valued model (left) and its real equivalent counterpart (center) in distinguishing a perfectly circular distribution from a second one as function of its circularity quotient. The third plot (right), instead, represents simply the differences among the first two.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Condition Monitoring}{xxxv}{part.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Healthy-Faulty Signal Classification}{xxxvii}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}State-of-the-Art}{xxxviii}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Baseline Machine Learning}{xxxviii}{subsection.5.1.1}\protected@file@percent }
\citation{deep_learning_vibration_gravity}
\citation{deep_learning_vibration_gravity}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Study in the frequency domain}{xxxix}{subsection.5.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Representation of a vibration signal in the time domain (left), in the frequency domain via FFT (center) and with its power spectrum (right).\relax }}{xxxix}{figure.caption.37}\protected@file@percent }
\newlabel{fig:example_stft}{{5.1}{xxxix}{Representation of a vibration signal in the time domain (left), in the frequency domain via FFT (center) and with its power spectrum (right).\relax }{figure.caption.37}{}}
\citation{deep_learning_vibration_gravity}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces State-of-the-art approaches for vibration data classification applied to predictive maintenance (source: \cite  {deep_learning_vibration_gravity}).\relax }}{xl}{figure.caption.38}\protected@file@percent }
\newlabel{fig:summary_hf_classification_methods}{{5.2}{xl}{State-of-the-art approaches for vibration data classification applied to predictive maintenance (source: \cite {deep_learning_vibration_gravity}).\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Bonfiglioli}{xl}{section.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Bonfiglioli logo.\relax }}{xl}{figure.caption.39}\protected@file@percent }
\newlabel{fig:bonfiglioli_logo}{{5.3}{xl}{Bonfiglioli logo.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Simulation Environment}{xl}{subsection.5.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Schematic representation of the experimental workbench used by Bonfiglioli.\relax }}{xli}{figure.caption.40}\protected@file@percent }
\newlabel{fig:bonfiglioli_experimental_setup}{{5.4}{xli}{Schematic representation of the experimental workbench used by Bonfiglioli.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Example of working cycle (from Prova-5) of the Bonfiglioli experimental setup.\relax }}{xli}{figure.caption.41}\protected@file@percent }
\newlabel{fig:bonfiglioli_example_working_cycle}{{5.5}{xli}{Example of working cycle (from Prova-5) of the Bonfiglioli experimental setup.\relax }{figure.caption.41}{}}
\citation{}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Datasets}{xlii}{subsection.5.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Summary of the main technical features of the datasets provided by Bonfiglioli and used in our analysis.\relax }}{xlii}{table.caption.42}\protected@file@percent }
\newlabel{tab:bonfiglioli_summary}{{5.1}{xlii}{Summary of the main technical features of the datasets provided by Bonfiglioli and used in our analysis.\relax }{table.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Baseline Classification Approach}{xlii}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Complex Spectrogram Classification}{xlii}{subsection.5.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Example of spectrograms derived from a signal in the Bonfiglioli dataset. For completeness, we represented also the power spectrum (right) and the phase spectrum (center). The leftmost one is instead our representation of the complex spectrum.\relax }}{xliii}{figure.caption.43}\protected@file@percent }
\newlabel{fig:example_bonfiglioli_spectrum}{{5.6}{xliii}{Example of spectrograms derived from a signal in the Bonfiglioli dataset. For completeness, we represented also the power spectrum (right) and the phase spectrum (center). The leftmost one is instead our representation of the complex spectrum.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Bonfiglioli - Results}{xliii}{section.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Binary classification of single Bonfiglioli datasets.\relax }}{xliv}{table.caption.44}\protected@file@percent }
\newlabel{tab:bonfigloli_ds_results}{{5.2}{xliv}{Binary classification of single Bonfiglioli datasets.\relax }{table.caption.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Multiclass Classification}{xliv}{subsection.5.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Training loops of real and complex-valued models for the Bonfiglioli multiclass classification problem.\relax }}{xlv}{figure.caption.45}\protected@file@percent }
\newlabel{fig:bonfiglioli_onecycle_results}{{5.7}{xlv}{Training loops of real and complex-valued models for the Bonfiglioli multiclass classification problem.\relax }{figure.caption.45}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Statistical estimators of the Bonfiglioli analysis.\relax }}{xlv}{table.caption.46}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Class Activation Maps}{xlv}{subsection.5.3.2}\protected@file@percent }
\citation{mendeley_dataset}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Confusion matrices of the Bonfiglioli multiclass classification problem.\relax }}{xlvi}{figure.caption.47}\protected@file@percent }
\newlabel{fig:bonfiglioli_onecycle_confmat}{{5.8}{xlvi}{Confusion matrices of the Bonfiglioli multiclass classification problem.\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces text\relax }}{xlvi}{figure.caption.48}\protected@file@percent }
\newlabel{fig:bonfiglioli_CAM_images}{{5.9}{xlvi}{text\relax }{figure.caption.48}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Mendelay Data}{xlvi}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Dataset Structure}{xlvi}{subsection.5.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Experimental setup for Mendeley data.\relax }}{xlvii}{figure.caption.49}\protected@file@percent }
\newlabel{fig:mendeley_setup}{{5.10}{xlvii}{Experimental setup for Mendeley data.\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Spectrograms of the four varying-speed conditions of Mendelay data.\relax }}{xlvii}{figure.caption.50}\protected@file@percent }
\newlabel{fig:mendelay_speed_changes}{{5.11}{xlvii}{Spectrograms of the four varying-speed conditions of Mendelay data.\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Mendeley Classification}{xlviii}{subsection.5.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Performances achieved over the Mendelay dataset constructing one-second long sub-signals.\relax }}{xlviii}{figure.caption.51}\protected@file@percent }
\newlabel{fig:mendeley_train_bad}{{5.12}{xlviii}{Performances achieved over the Mendelay dataset constructing one-second long sub-signals.\relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Performances achieved over the Mendelay dataset constructing 0.25 seconds long sub-signals.\relax }}{xlix}{figure.caption.52}\protected@file@percent }
\newlabel{fig:mendeley_train_final}{{5.13}{xlix}{Performances achieved over the Mendelay dataset constructing 0.25 seconds long sub-signals.\relax }{figure.caption.52}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Generalization performances of real and complex-valued models over the Mendelay dataset.\relax }}{xlix}{table.caption.53}\protected@file@percent }
\newlabel{tab:mendeley_generalization}{{5.4}{xlix}{Generalization performances of real and complex-valued models over the Mendelay dataset.\relax }{table.caption.53}{}}
\citation{*}
\bibdata{bibliography}
\bibcite{trabelsi2018deep}{1}
\bibcite{Messerschmitt_stationary_points}{2}
\bibcite{Hualiang_nonlinear}{3}
\bibcite{Dramsch_seismic}{4}
\bibcite{stein_complex_analysis}{5}
\bibcite{kreutzdelgado2009complex}{6}
\bibcite{Nitta_complexBP}{7}
\bibcite{barrachina2021complexvalued}{8}
\bibcite{Virtue:EECS-2019-126}{9}
\bibcite{hirose_cvnn}{10}
\bibcite{amin_wirtinger}{11}
\bibcite{xavier_init}{12}
\bibcite{he2015delving}{13}
\bibcite{cogswell2016reducing}{14}
\bibcite{guberman2016complex}{15}
\bibcite{Koutsougeras_siglog}{16}
\bibcite{DBLP:journals/corr/ArjovskySB15}{17}
\bibcite{deep_learning_vibration_gravity}{18}
\bibcite{mendeley_dataset}{19}
\bibcite{ziller2021complexvalued}{20}
\bibcite{article}{21}
\bibcite{4682548}{22}
\bibcite{virtue2017better}{23}
\bibcite{GARDNER2021116245}{24}
\bibcite{ajakan2015domainadversarial}{25}
\bibcite{ganin2016domainadversarial}{26}
\bibcite{reichert2014neuronal}{27}
\bibcite{scardapane2018complexvalued}{28}
\bibcite{shen2018wasserstein}{29}
\bibcite{schlomer_nico_2021_5636188}{30}
\bibcite{Farris_visual_complex_analysis}{31}
\bibstyle{ieeetr}
\citation{trabelsi2018deep}
\citation{xavier_init}
\citation{he2015delving}
\citation{xavier_init}
\citation{he2015delving}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Mathematical Proofs}{liii}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:cmplx_optim}{{A}{liii}{Mathematical Proofs}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Complex Weights Initialization \cite  {trabelsi2018deep}}{liii}{section.A.1}\protected@file@percent }
\newlabel{app:weight_init}{{A.1}{liii}{Complex Weights Initialization \cite {trabelsi2018deep}}{section.A.1}{}}
\citation{Messerschmitt_stationary_points}
\citation{MESSERSCHMITT_STATIONARY_POINTS}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Stationary points of a real-valued function of a complex variable \cite  {Messerschmitt_stationary_points}}{liv}{section.A.2}\protected@file@percent }
\citation{Hualiang_nonlinear}
\citation{HUALIANG_NONLINEAR}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Steepest complex gradient descent \cite  {Hualiang_nonlinear}}{lv}{section.A.3}\protected@file@percent }
\gdef \@abspage@last{55}
